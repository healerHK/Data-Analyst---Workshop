{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/healerHK/Data-Analyst---Workshop/blob/main/LeNet5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDbJWoO1yO8e"
      },
      "source": [
        "# Image Classification with CNN - LeNet5 architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzQxqD6HyO8i"
      },
      "source": [
        "In this exercise, we will apply the LeNet5 algorithm to the Fashion MNIST dataset and improve your performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFyVotRvyO8j"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTHLyL1fyO8j",
        "outputId": "62ed9c01-79f0-430d-cd96-7be882bea6bb",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# TODO: Load the dataset\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# # # If your computer is slow, try to use a subset of data, e.g.\n",
        "# X_train = X_train[:10000]\n",
        "# y_train = y_train[:10000]\n",
        "# X_test = X_test[:2000]\n",
        "# y_test = y_test[:2000]\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ShXIANyO8l"
      },
      "source": [
        "As you already know, this dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BvNG0PbyO8l"
      },
      "source": [
        "You can have a look at some images if needed, even if you already know them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "lnjqgv-GyO8m",
        "outputId": "c30facae-78a3-4c81-8339-861794531eeb",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx], cmap='gray_r')\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdYH6XW1yO8n"
      },
      "source": [
        "Make the data preparation and preprocessing: scale and reshape the data, put the labels to the good shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fjv8XMPByO8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4727183-fb92-4b41-fefd-aa797c933ce8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "X_train_norm = X_train/255\n",
        "X_test_norm = X_test/255\n",
        "\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], X_train_norm.shape[1], X_train_norm.shape[2], 1)\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], X_test_norm.shape[1], X_test_norm.shape[2], 1)\n",
        "\n",
        "X_train_norm.shape #Should be (60000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9LKzxR9yO8o"
      },
      "source": [
        "Now build the LeNet5 architecture. You can reuse the one of the course, or try to build it by yourself.\n",
        "\n",
        "The architecture is the following:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1WteTU2FPIVMkBKmMxGpFm5OjsX-szTbB\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GKyMFlL6yO8o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "97b4c3e7-f833-46b6-fc12-b003c2f7be94"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ C1 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │            \u001b[38;5;34m60\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ S2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ C3 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m880\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ S4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ C5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │        \u001b[38;5;34m48,120\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ F6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)             │        \u001b[38;5;34m10,164\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m850\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ C1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ S2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ C3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">880</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ S4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ C5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">48,120</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ F6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,164</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">850</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m60,074\u001b[0m (234.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,074</span> (234.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m60,074\u001b[0m (234.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,074</span> (234.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
        "\n",
        "\n",
        "def lenet5():\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer C1\n",
        "    model.add(Conv2D(filters=6, name='C1', kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "    # Layer S2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S2'))\n",
        "    # Layer C3\n",
        "    model.add(Conv2D(filters=16, name='C3', kernel_size=(3, 3), activation='relu'))\n",
        "    # Layer S4\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S4'))\n",
        "    # Before going into layer C5, we flatten our units\n",
        "    model.add(Flatten())\n",
        "    # Layer C5\n",
        "    model.add(Dense(120, activation = 'relu', name='C5'))\n",
        "    # Layer F6\n",
        "    model.add(Dense(84, activation = 'relu', name='F6'))\n",
        "    # Output layer\n",
        "    model.add(Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "    return model\n",
        "lenet5().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1qBEauqyO8p"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPL3aKnyyO8p",
        "outputId": "59106153-d3c9-4c60-d6e6-7fab1036d3c0",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 128ms/step - accuracy: 0.3673 - loss: 2.0170 - val_accuracy: 0.6549 - val_loss: 0.9291\n",
            "Epoch 2/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6944 - loss: 0.8213 - val_accuracy: 0.7383 - val_loss: 0.6949\n",
            "Epoch 3/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7488 - loss: 0.6477 - val_accuracy: 0.7758 - val_loss: 0.6015\n",
            "Epoch 4/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7882 - loss: 0.5622 - val_accuracy: 0.7775 - val_loss: 0.5744\n",
            "Epoch 5/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8047 - loss: 0.5250 - val_accuracy: 0.8127 - val_loss: 0.5125\n",
            "Epoch 6/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8257 - loss: 0.4803 - val_accuracy: 0.8174 - val_loss: 0.4917\n",
            "Epoch 7/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8348 - loss: 0.4546 - val_accuracy: 0.8336 - val_loss: 0.4610\n",
            "Epoch 8/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8414 - loss: 0.4421 - val_accuracy: 0.8350 - val_loss: 0.4555\n",
            "Epoch 9/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8494 - loss: 0.4197 - val_accuracy: 0.8371 - val_loss: 0.4486\n",
            "Epoch 10/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8539 - loss: 0.4056 - val_accuracy: 0.8511 - val_loss: 0.4186\n",
            "Epoch 11/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8609 - loss: 0.3904 - val_accuracy: 0.8508 - val_loss: 0.4158\n",
            "Epoch 12/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8637 - loss: 0.3816 - val_accuracy: 0.8570 - val_loss: 0.4066\n",
            "Epoch 13/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8660 - loss: 0.3755 - val_accuracy: 0.8605 - val_loss: 0.3964\n",
            "Epoch 14/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8734 - loss: 0.3533 - val_accuracy: 0.8633 - val_loss: 0.3825\n",
            "Epoch 15/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8774 - loss: 0.3460 - val_accuracy: 0.8607 - val_loss: 0.3908\n",
            "Epoch 16/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8750 - loss: 0.3499 - val_accuracy: 0.8669 - val_loss: 0.3740\n",
            "Epoch 17/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8799 - loss: 0.3353 - val_accuracy: 0.8682 - val_loss: 0.3693\n",
            "Epoch 18/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8816 - loss: 0.3299 - val_accuracy: 0.8695 - val_loss: 0.3619\n",
            "Epoch 19/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8863 - loss: 0.3208 - val_accuracy: 0.8709 - val_loss: 0.3602\n",
            "Epoch 20/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8866 - loss: 0.3193 - val_accuracy: 0.8722 - val_loss: 0.3565\n",
            "Epoch 21/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8850 - loss: 0.3188 - val_accuracy: 0.8744 - val_loss: 0.3494\n",
            "Epoch 22/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8872 - loss: 0.3152 - val_accuracy: 0.8723 - val_loss: 0.3556\n",
            "Epoch 23/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8867 - loss: 0.3135 - val_accuracy: 0.8756 - val_loss: 0.3520\n",
            "Epoch 24/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8871 - loss: 0.3131 - val_accuracy: 0.8803 - val_loss: 0.3375\n",
            "Epoch 25/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8931 - loss: 0.2991 - val_accuracy: 0.8794 - val_loss: 0.3378\n",
            "Epoch 26/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8946 - loss: 0.2939 - val_accuracy: 0.8795 - val_loss: 0.3365\n",
            "Epoch 27/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8904 - loss: 0.3042 - val_accuracy: 0.8784 - val_loss: 0.3377\n",
            "Epoch 28/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8950 - loss: 0.2913 - val_accuracy: 0.8796 - val_loss: 0.3396\n",
            "Epoch 29/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8955 - loss: 0.2914 - val_accuracy: 0.8779 - val_loss: 0.3407\n",
            "Epoch 30/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8969 - loss: 0.2880 - val_accuracy: 0.8845 - val_loss: 0.3283\n",
            "Epoch 31/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8984 - loss: 0.2833 - val_accuracy: 0.8765 - val_loss: 0.3420\n",
            "Epoch 32/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8944 - loss: 0.2879 - val_accuracy: 0.8846 - val_loss: 0.3245\n",
            "Epoch 33/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9007 - loss: 0.2770 - val_accuracy: 0.8846 - val_loss: 0.3282\n",
            "Epoch 34/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9010 - loss: 0.2731 - val_accuracy: 0.8832 - val_loss: 0.3228\n",
            "Epoch 35/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9034 - loss: 0.2690 - val_accuracy: 0.8835 - val_loss: 0.3267\n",
            "Epoch 36/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9003 - loss: 0.2773 - val_accuracy: 0.8811 - val_loss: 0.3229\n",
            "Epoch 37/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9026 - loss: 0.2711 - val_accuracy: 0.8865 - val_loss: 0.3186\n",
            "Epoch 38/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9029 - loss: 0.2692 - val_accuracy: 0.8840 - val_loss: 0.3226\n",
            "Epoch 39/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9044 - loss: 0.2632 - val_accuracy: 0.8879 - val_loss: 0.3166\n",
            "Epoch 40/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9046 - loss: 0.2604 - val_accuracy: 0.8833 - val_loss: 0.3163\n",
            "Epoch 41/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9039 - loss: 0.2640 - val_accuracy: 0.8837 - val_loss: 0.3291\n",
            "Epoch 42/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9045 - loss: 0.2645 - val_accuracy: 0.8886 - val_loss: 0.3153\n",
            "Epoch 43/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9073 - loss: 0.2549 - val_accuracy: 0.8875 - val_loss: 0.3126\n",
            "Epoch 44/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9090 - loss: 0.2538 - val_accuracy: 0.8890 - val_loss: 0.3134\n",
            "Epoch 45/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9102 - loss: 0.2499 - val_accuracy: 0.8862 - val_loss: 0.3179\n",
            "Epoch 46/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9077 - loss: 0.2529 - val_accuracy: 0.8895 - val_loss: 0.3109\n",
            "Epoch 47/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9071 - loss: 0.2522 - val_accuracy: 0.8909 - val_loss: 0.3082\n",
            "Epoch 48/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9109 - loss: 0.2498 - val_accuracy: 0.8886 - val_loss: 0.3190\n",
            "Epoch 49/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9086 - loss: 0.2492 - val_accuracy: 0.8902 - val_loss: 0.3099\n",
            "Epoch 50/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9105 - loss: 0.2464 - val_accuracy: 0.8839 - val_loss: 0.3209\n",
            "Epoch 51/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9089 - loss: 0.2494 - val_accuracy: 0.8919 - val_loss: 0.3083\n",
            "Epoch 52/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9051 - loss: 0.2526 - val_accuracy: 0.8892 - val_loss: 0.3108\n",
            "Epoch 53/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9111 - loss: 0.2423 - val_accuracy: 0.8895 - val_loss: 0.3143\n",
            "Epoch 54/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9110 - loss: 0.2433 - val_accuracy: 0.8907 - val_loss: 0.3079\n",
            "Epoch 55/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9127 - loss: 0.2386 - val_accuracy: 0.8898 - val_loss: 0.3090\n",
            "Epoch 56/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9071 - loss: 0.2515 - val_accuracy: 0.8834 - val_loss: 0.3207\n",
            "Epoch 57/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9115 - loss: 0.2396 - val_accuracy: 0.8880 - val_loss: 0.3053\n",
            "Epoch 58/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9138 - loss: 0.2376 - val_accuracy: 0.8897 - val_loss: 0.3103\n",
            "Epoch 59/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9164 - loss: 0.2341 - val_accuracy: 0.8956 - val_loss: 0.3000\n",
            "Epoch 60/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9163 - loss: 0.2301 - val_accuracy: 0.8950 - val_loss: 0.3008\n",
            "Epoch 61/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9183 - loss: 0.2252 - val_accuracy: 0.8880 - val_loss: 0.3074\n",
            "Epoch 62/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9134 - loss: 0.2356 - val_accuracy: 0.8919 - val_loss: 0.3045\n",
            "Epoch 63/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9177 - loss: 0.2260 - val_accuracy: 0.8933 - val_loss: 0.3036\n",
            "Epoch 64/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9173 - loss: 0.2264 - val_accuracy: 0.8926 - val_loss: 0.3028\n",
            "Epoch 65/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9200 - loss: 0.2227 - val_accuracy: 0.8937 - val_loss: 0.3057\n",
            "Epoch 66/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9175 - loss: 0.2250 - val_accuracy: 0.8967 - val_loss: 0.2951\n",
            "Epoch 67/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9193 - loss: 0.2219 - val_accuracy: 0.8936 - val_loss: 0.3046\n",
            "Epoch 68/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9195 - loss: 0.2207 - val_accuracy: 0.8962 - val_loss: 0.2963\n",
            "Epoch 69/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9202 - loss: 0.2169 - val_accuracy: 0.8964 - val_loss: 0.3033\n",
            "Epoch 70/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9193 - loss: 0.2218 - val_accuracy: 0.8917 - val_loss: 0.3076\n",
            "Epoch 71/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9195 - loss: 0.2191 - val_accuracy: 0.8895 - val_loss: 0.3093\n",
            "Epoch 72/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9185 - loss: 0.2172 - val_accuracy: 0.8900 - val_loss: 0.3080\n",
            "Epoch 73/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9179 - loss: 0.2244 - val_accuracy: 0.8967 - val_loss: 0.2980\n",
            "Epoch 74/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9206 - loss: 0.2158 - val_accuracy: 0.8964 - val_loss: 0.2971\n",
            "Epoch 75/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9201 - loss: 0.2168 - val_accuracy: 0.8924 - val_loss: 0.3061\n",
            "Epoch 76/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9205 - loss: 0.2148 - val_accuracy: 0.8919 - val_loss: 0.3034\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ab9d190d0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# TODO: Compile and fit your model\n",
        "import os\n",
        "\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "model = lenet5()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define now our callbacks\n",
        "# callbacks = [EarlyStopping(monitor='val_loss', patience=10), TensorBoard(log_dir='./keras-logs', histogram_freq=0, write_graph=True, write_images=True)]\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "\n",
        "# Finally fit the model\n",
        "model.fit(x=X_train_norm, y=y_train_cat, validation_data=(X_test_norm, y_test_cat), epochs=100, batch_size=2048, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf-SqjjOyO8q"
      },
      "source": [
        "Have a look at the tensorboard and see if it gives a deeper understanding of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2FTj7TSyO8q"
      },
      "source": [
        "Compute then the accuracy of your model. Is it better than a regular MLP used before?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPjJoMQZyO8q",
        "outputId": "58b3c451-41aa-4ed5-d2f1-3a562b7e56a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "accuracy on train with CNN: 0.9199166666666667\n",
            "accuracy on test with CNN: 0.8919\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size = 1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size = batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vulsgHiyO8q"
      },
      "source": [
        "We will now add image augmentation to improve our results, especially we will try to reduce overfitting this way.\n",
        "\n",
        "To do so, you can use `ImageDataGenerator` from Keras that makes all the work for you (including rescaling), with the following parameter:\n",
        "* `horizontal_flip=True`\n",
        "\n",
        "For more info about how the `ImageDataGenerator` works, you can check out [this article](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/).\n",
        "\n",
        "Begin by creating an object `ImageDataGenerator` with this parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-19T11:58:37.442182Z",
          "start_time": "2020-08-19T11:58:37.438397Z"
        },
        "id": "pas-fMSIyO8q"
      },
      "outputs": [],
      "source": [
        "# TODO: Instantiate an ImageDataGenerator object\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7nCnu9syO8r"
      },
      "source": [
        "Finally, you can train your model using this generator, with the method `fit_generator` of your model and the method `flow` of your `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt6wXa3IyO8r",
        "outputId": "d64a8852-9765-422e-bbae-570a6478f4fb",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.8310 - loss: 0.6186 - val_accuracy: 0.8842 - val_loss: 0.3208\n",
            "Epoch 2/100\n",
            "\u001b[1m 1/58\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8750 - loss: 0.3437"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8750 - loss: 0.3437 - val_accuracy: 0.8862 - val_loss: 0.3196\n",
            "Epoch 3/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8942 - loss: 0.2904 - val_accuracy: 0.8910 - val_loss: 0.3045\n",
            "Epoch 4/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8945 - loss: 0.2771 - val_accuracy: 0.8922 - val_loss: 0.3062\n",
            "Epoch 5/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.8980 - loss: 0.2768 - val_accuracy: 0.8851 - val_loss: 0.3160\n",
            "Epoch 6/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8926 - loss: 0.2987 - val_accuracy: 0.8858 - val_loss: 0.3142\n",
            "Epoch 7/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 0.8979 - loss: 0.2743 - val_accuracy: 0.8886 - val_loss: 0.3053\n",
            "Epoch 8/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8975 - loss: 0.2780 - val_accuracy: 0.8933 - val_loss: 0.2975\n",
            "Epoch 9/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9039 - loss: 0.2619 - val_accuracy: 0.8929 - val_loss: 0.2950\n",
            "Epoch 10/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9111 - loss: 0.2661 - val_accuracy: 0.8927 - val_loss: 0.2950\n",
            "Epoch 11/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9084 - loss: 0.2523 - val_accuracy: 0.8944 - val_loss: 0.2964\n",
            "Epoch 12/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8965 - loss: 0.2802 - val_accuracy: 0.8936 - val_loss: 0.2962\n",
            "Epoch 13/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9098 - loss: 0.2477 - val_accuracy: 0.8937 - val_loss: 0.2927\n",
            "Epoch 14/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8975 - loss: 0.2753 - val_accuracy: 0.8914 - val_loss: 0.3040\n",
            "Epoch 15/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.9022 - loss: 0.2616 - val_accuracy: 0.8935 - val_loss: 0.2950\n",
            "Epoch 16/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9307 - loss: 0.2073 - val_accuracy: 0.8944 - val_loss: 0.2950\n",
            "Epoch 17/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 50ms/step - accuracy: 0.9079 - loss: 0.2498 - val_accuracy: 0.8977 - val_loss: 0.2946\n",
            "Epoch 18/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9092 - loss: 0.2405 - val_accuracy: 0.8952 - val_loss: 0.2979\n",
            "Epoch 19/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9101 - loss: 0.2416 - val_accuracy: 0.8935 - val_loss: 0.2988\n",
            "Epoch 20/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9092 - loss: 0.2585 - val_accuracy: 0.8957 - val_loss: 0.2943\n",
            "Epoch 21/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9098 - loss: 0.2429 - val_accuracy: 0.8967 - val_loss: 0.2908\n",
            "Epoch 22/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9180 - loss: 0.1994 - val_accuracy: 0.8961 - val_loss: 0.2929\n",
            "Epoch 23/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9131 - loss: 0.2346 - val_accuracy: 0.8975 - val_loss: 0.2870\n",
            "Epoch 24/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9170 - loss: 0.2426 - val_accuracy: 0.8976 - val_loss: 0.2875\n",
            "Epoch 25/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.9134 - loss: 0.2324 - val_accuracy: 0.8952 - val_loss: 0.2917\n",
            "Epoch 26/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9160 - loss: 0.2169 - val_accuracy: 0.8973 - val_loss: 0.2884\n",
            "Epoch 27/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9121 - loss: 0.2383 - val_accuracy: 0.8970 - val_loss: 0.2843\n",
            "Epoch 28/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9062 - loss: 0.2525 - val_accuracy: 0.8966 - val_loss: 0.2855\n",
            "Epoch 29/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9143 - loss: 0.2314 - val_accuracy: 0.8995 - val_loss: 0.2852\n",
            "Epoch 30/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9189 - loss: 0.2572 - val_accuracy: 0.8955 - val_loss: 0.2873\n",
            "Epoch 31/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9158 - loss: 0.2325 - val_accuracy: 0.8973 - val_loss: 0.2916\n",
            "Epoch 32/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9180 - loss: 0.2034 - val_accuracy: 0.8969 - val_loss: 0.2917\n",
            "Epoch 33/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.9166 - loss: 0.2292 - val_accuracy: 0.8909 - val_loss: 0.2966\n",
            "Epoch 34/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9131 - loss: 0.2387 - val_accuracy: 0.8951 - val_loss: 0.2914\n",
            "Epoch 35/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9152 - loss: 0.2283 - val_accuracy: 0.8955 - val_loss: 0.2955\n",
            "Epoch 36/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9160 - loss: 0.2529 - val_accuracy: 0.8965 - val_loss: 0.2946\n",
            "Epoch 37/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9152 - loss: 0.2279 - val_accuracy: 0.8984 - val_loss: 0.2846\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ab934888a10>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# TODO: train your model\n",
        "batch_size = 1024\n",
        "model.fit(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n",
        "                    validation_data=(X_test_norm, y_test_cat), callbacks=callbacks,\n",
        "                    steps_per_epoch=len(X_train_norm) // batch_size, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuzFke8pyO8r"
      },
      "source": [
        "Recompute the accuracy of your model, does it improve your performances with data augmentation?\n",
        "\n",
        "=> Yes, it is improved a little bit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsTm86tuyO8r",
        "outputId": "345e6dc2-6759-46ed-e8d3-862556ae9ff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n",
            "accuracy on train with CNN: 0.9248\n",
            "accuracy on test with CNN: 0.8984\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size = 1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size = batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOzkdGf7yO8s"
      },
      "source": [
        "You can now try to improve even more your results. For example, add more parameters to your `ImageDataGenerator`, play with some hyperparameters, and so on..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
